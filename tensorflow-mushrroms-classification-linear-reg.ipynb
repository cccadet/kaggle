{"cells": [{"execution_count": null, "source": ["#Aux\u00edlio do Tutorial: https://matheusfacure.github.io/2017/05/12/tensorflow-essencial/\n", "\n", "# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import tensorflow as tf\n", "import gzip\n", "import pickle\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn import preprocessing\n", "from sklearn.preprocessing import MinMaxScaler\n", "from sklearn.model_selection import train_test_split\n", "import os # para criar pastas\n", "from sklearn.metrics import r2_score, accuracy_score\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "8f6f5449-9d2b-4f13-b112-b5730f22ce66", "_uuid": "ba316cf9fbcd289d0d2a1635414f48d64f3a49ed"}}, {"execution_count": null, "source": ["df = pd.read_csv('../input/mushrooms.csv')\n", "df.head()"], "cell_type": "code", "outputs": [], "metadata": {}}, {"execution_count": null, "source": ["le = preprocessing.LabelEncoder()\n", "df_encoded = df.apply(le.fit_transform)\n", "list(le.classes_)\n", "#list(le.inverse_transform([2, 2, 1]))\n", "\n", "df_encoded.astype(float)\n", "scaler = MinMaxScaler()\n", "df_encoded[df_encoded.columns] = scaler.fit_transform(df_encoded[df_encoded.columns])\n", "df_encoded.head()\n", "\n", "X = df_encoded.drop(['class'], axis=1)\n", "y = df_encoded['class']"], "cell_type": "code", "outputs": [], "metadata": {}}, {"execution_count": null, "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n", "print('Formato dos dados:', X_train.shape, y_train.shape)\n"], "cell_type": "code", "outputs": [], "metadata": {}}, {"execution_count": null, "source": ["# definindo constantes\n", "lr = 1e-2 # taxa de aprendizado\n", "n_iter = 2501 # n\u00famero de itera\u00e7\u00f5es de treino\n", "n_inputs = X_train.shape[1] # n\u00famero de vari\u00e1veis independentes\n", "n_outputs = 1 # n\u00famero de vari\u00e1veis dependentes\n", "\n", "graph = tf.Graph() # isso cria um grafo\n", "with graph.as_default(): # isso abre o grafo para que possamos colocar opera\u00e7\u00f5es e vari\u00e1veis dentro dele.\n", "    tf.set_random_seed(1)\n", "    \n", "    # adiciona as vari\u00e1veis ao grafo\n", "    W = tf.Variable(tf.truncated_normal([n_inputs, n_outputs], stddev=.1), name='Weight')\n", "    b = tf.Variable(tf.zeros([n_outputs]), name='bias')\n", "\n", "\n", "    ######################################\n", "    # Monta o modelo de regress\u00e3o linear #\n", "    ######################################\n", "\n", "    # Camadas de Inputs\n", "    x_input = tf.placeholder(tf.float32, [None, n_inputs], name='X_input')\n", "    y_input = tf.placeholder(tf.float32, [None, n_outputs], name='y_input')\n", "\n", "    # Camada Linear\n", "    y_pred = tf.add(tf.matmul(x_input, W), b, name='y_pred')\n", "\n", "    # Camada de custo ou fun\u00e7\u00e3o objetivo\n", "    EQM = tf.reduce_mean(tf.square(y_pred - y_input), name=\"EQM\")\n", "\n", "    # otimizador\n", "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(EQM)\n", "\n", "    # inicializador\n", "    init = tf.global_variables_initializer()\n", "\n", "    # para salvar o modelo treinado\n", "    saver = tf.train.Saver()\n"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "source": ["# criamos uma pasta para salvar o modelo\n", "if not os.path.exists('tmp'):\n", "    os.makedirs('tmp')\n", "\n", "# abrimos a sess\u00e3o tf\n", "with tf.Session(graph=graph) as sess:\n", "    sess.run(init) # iniciamos as vari\u00e1veis\n", "    \n", "    # cria um feed_dict\n", "    feed_dict = {x_input: X_train, y_input: y_train.values.reshape(-1,1)}\n", "    \n", "    # realizamos as itera\u00e7\u00f5es de treino\n", "    for step in range(n_iter + 1):\n", "        \n", "        # executa algumas opera\u00e7\u00f5es do grafo\n", "        _, l = sess.run([optimizer, EQM], feed_dict=feed_dict)\n", "        \n", "        if (step % 500) == 0:\n", "            print('Custo na itera\u00e7\u00e3o %d: %.2f \\r' % (step, l), end='')\n", "            saver.save(sess, \"./tmp/my_model.ckpt\")\n"], "cell_type": "code", "outputs": [], "metadata": {}}, {"execution_count": null, "source": ["# novamente, abrimos a sess\u00e3o tf\n", "with tf.Session(graph=graph) as sess:\n", "    \n", "    # restauramos o valor das vari\u00e1veis \n", "    saver.restore(sess, \"./tmp/my_model.ckpt\", )\n", "    \n", "    # rodamos o n\u00f3 de previs\u00e3o no grafo\n", "    y_hat = sess.run(y_pred, feed_dict={x_input: X_test})\n", "    \n", "    print('\\nR2: %.3f' % r2_score(y_pred=y_hat, y_true=y_test))\n", "    print('\\nAccuracy %.3f' % accuracy_score(y_test, y_hat.round(), normalize=True))\n"], "cell_type": "code", "outputs": [], "metadata": {}}, {"execution_count": null, "source": [], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "nbconvert_exporter": "python", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "version": "3.6.3", "file_extension": ".py"}}}